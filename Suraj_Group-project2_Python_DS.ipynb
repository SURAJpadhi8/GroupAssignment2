{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c8d7b8b",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Arial; font-weight: bold; font-size: 2em; color: #FFA500; text-align: center;\">\n",
    "    Python Group Assignment-2\n",
    "</div>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13e164c",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Arial; font-weight: bold; font-size: 1.3em; color: #FFA500; text-align: center;\">\n",
    "     Import the required libraries and load the data:\n",
    "</div>   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb84ae90",
   "metadata": {},
   "source": [
    "### Question-1 Load the required libraries and read the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e999399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.stats import zscore\n",
    "from scipy.spatial import distance\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0549f974",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('renttherunway.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbc273d",
   "metadata": {},
   "source": [
    "### Question- 2  Check the first few samples, shape, info of the data and try to familiarize yourself with different features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b32cc7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb520aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d4df96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7523408f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Rows: ', df.shape[0])\n",
    "print('Columns: ', df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6285e4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4869c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469a0c73",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Arial; font-weight: bold; font-size: 1.3em; color: #FFA500; text-align: center;\">\n",
    "     Data cleansing and Exploratory data analysis:\n",
    "</div>   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d37d5f",
   "metadata": {},
   "source": [
    "### Question- 3  Check if there are any duplicate records in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915ed488",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.duplicated()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496e70c9",
   "metadata": {},
   "source": [
    "### Question- 4 Drop the columns which you think redundant for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1186f51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3dc707",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['item_id','review_text','review_date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adffeecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa52cf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ca1b07",
   "metadata": {},
   "source": [
    "### Question- 5 Check the column 'weight', Is there any presence of string data? If yes, remove the string data and convert to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a4d5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = df[['weight']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88a1402",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weight'] = df['weight'].str[:-3].astype(float)\n",
    "df['weight'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab12219",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"weight\"].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0d5bc6",
   "metadata": {},
   "source": [
    "### Question-6  Check the unique categories for the column 'rented for' and group 'party: cocktail' category with 'party'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5010a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_categories = df['rented for'].unique()\n",
    "print(\"Unique categories for 'rented for':\", unique_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d889718",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rented for'] = df['rented for'].replace('party: cocktail', 'party')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6458d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_categories = df['rented for'].unique()\n",
    "print(\"Updated unique categories for 'rented for':\", updated_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9956e359",
   "metadata": {},
   "source": [
    "### Question-7 The column 'height' is in feet with a quotation mark, Convert to inches with float datatype. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4464273",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['height'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c35abf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "df['height'] = df['height'].astype(str)\n",
    "\n",
    "def convert_to_inches(height):\n",
    "    match = re.match(r'(\\d+)\\'\\s*(\\d+)?', height)\n",
    "    if match:\n",
    "        feet = int(match.group(1))\n",
    "        inches = int(match.group(2)) if match.group(2) else 0\n",
    "        return (feet * 12) + inches\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "df['height'] = df['height'].apply(convert_to_inches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b88dde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unique heights (after conversion):\", df['height'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d030cd3",
   "metadata": {},
   "source": [
    "### Question-8  Check for missing values in each column of the dataset? If it exists, impute them with appropriate methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d84878",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "numerical_cols = df.select_dtypes(include=['float', 'int']).columns\n",
    "for col in numerical_cols:\n",
    "    df[col].fillna(df[col].mean(), inplace=True)\n",
    "\n",
    "missing_values_after_imputation = df.isnull().sum()\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8365c3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df.isnull().sum()*100/len(df)\n",
    "\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006b805a",
   "metadata": {},
   "source": [
    "### Question-9  Check the statistical summary for the numerical and categorical columns and write your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd400e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_data = df.describe()\n",
    "numerical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142890e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_summary= df.describe(include=['object'])\n",
    "\n",
    "print(\"\\nStatistical summary for categorical columns:\")\n",
    "categorical_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4bda3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_data = df.select_dtypes(include=['number']).columns\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "numerical_data = df[numerical_data].describe()\n",
    "numerical_data = df[['size', 'age']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3943d249",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_summary = {}\n",
    "for column in categorical_columns:\n",
    "    categorical_summary[column] = df[column].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e8282e",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02fa289",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column, summary in categorical_summary.items():\n",
    "    summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ffe7e6",
   "metadata": {},
   "source": [
    "### Question-10  Are there outliers present in the column age? If yes, treat them with the appropriate method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6fa272",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_age = df['age'].mean()\n",
    "std_age = df['age'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d35729",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 3 * std_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4b09df",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = df[(df['age'] - mean_age).abs() > threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47efa4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072f8c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_age = df['age'].median()\n",
    "df.loc[outliers.index, 'age'] = median_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ce6b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a114fc",
   "metadata": {},
   "source": [
    "### Question-11  Check the distribution of the different categories in the column 'rented for' using appropriate plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64cdf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_counts = df['rented for'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cae6f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=category_counts.index, y=category_counts.values)\n",
    "plt.title('Distribution of Categories in the \"rented for\" Column')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a2a4aa",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Arial; font-weight: bold; font-size: 1.3em; color: #FFA500; text-align: center;\">\n",
    "     Data Preparation for model building:\n",
    "</div>   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99d8f95",
   "metadata": {},
   "source": [
    "### Question-12  Encode the categorical variables in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189175c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = []\n",
    "\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == 'object':\n",
    "        categorical_columns.append(column)\n",
    "\n",
    "print(\"Categorical columns:\", categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a614e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for column in df.select_dtypes(include=['object']).columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bedbad",
   "metadata": {},
   "source": [
    "### Question-13  Standardize the data, so that the values are within a particular range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3abc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "standardized_data = scaler.fit_transform(numerical_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fffad53",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Arial; font-weight: bold; font-size: 1.3em; color: #FFA500; text-align: center;\">\n",
    "     Principal Component Analysis and Clustering:\n",
    "</div>   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0180657",
   "metadata": {},
   "source": [
    "### Question-14   Apply PCA on the above dataset and determine the number of PCA components to be used so that 90-95% of the variance in data is explained by the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bd1513",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = np.isnan(standardized_data).sum()\n",
    "\n",
    "infinity_values = np.isinf(standardized_data).sum()\n",
    "\n",
    "data_max = np.max(standardized_data)\n",
    "\n",
    "missing_values, infinity_values, data_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f692893",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(standardized_data)\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_variance = explained_variance_ratio.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d392ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 0\n",
    "for i, var in enumerate(cumulative_variance):\n",
    "    if var >= 0.90:\n",
    "        n_components = i + 1\n",
    "        break\n",
    "print(f\"Number of components to explain 90% of the variance: {n_components}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fec7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components_95 = 0\n",
    "for i, var in enumerate(cumulative_variance):\n",
    "    if var >= 0.95:\n",
    "        n_components_95 = i + 1 \n",
    "        break\n",
    "\n",
    "print(f\"Number of components to explain 95% of the variance: {n_components_95}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194175f1",
   "metadata": {},
   "source": [
    "### Question-15   Apply K-means clustering and segment the data. (You may use original data or PCA transformed data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce7a0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "clusters = kmeans.fit_predict(standardized_data)\n",
    "\n",
    "df['Cluster'] = np.nan\n",
    "df.loc[numerical_data.index, 'Cluster'] = clusters\n",
    "\n",
    "print(df[['size', 'age', 'Cluster']].dropna().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f469c42",
   "metadata": {},
   "source": [
    "### Question-15   a. Find the optimal K Value using elbow plot for K Means clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcad795",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "numerical_data = df[['size', 'age']].dropna()\n",
    "\n",
    "ssd = []\n",
    "for k in tqdm(range(1, 11)):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(standardized_data)\n",
    "    ssd.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 11), ssd, 'bo-', linewidth=2)\n",
    "plt.title('Elbow Plot for Optimal K Value')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Sum of Squared Distances')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f351844b",
   "metadata": {},
   "source": [
    "### Question-15  b. Build a Kmeans clustering model using the obtained optimal K value from the elbow plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1e5122",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=100)\n",
    "\n",
    "kmeans.fit(pca.transform(standardized_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeabb0b6",
   "metadata": {},
   "source": [
    "### Question-15  c. Compute silhouette score for evaluating the quality of the K Means clustering technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88146936",
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_avg = silhouette_score(standardized_data, clusters)\n",
    "\n",
    "silhouette_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d2c008",
   "metadata": {},
   "source": [
    "### Question-16  Apply Agglomerative clustering and segment the data. (You may use original data or PCA transformed data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075b8994",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "scaled_features_df = pd.DataFrame(standardized_data)\n",
    "scaled_features_df = shuffle(scaled_features_df, random_state=42).sample(frac=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b73455e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merg = linkage(scaled_features_df, method= 'ward') \n",
    "dendrogram(merg, leaf_rotation = 90,) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd7ec87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(index=range(19158))\n",
    "values = list(range(19158)) \n",
    "df['column_name'] = values\n",
    "agg_clustering = AgglomerativeClustering(n_clusters=3)\n",
    "agg_clusters = agg_clustering.fit_predict(scaled_features_df)\n",
    "\n",
    "df['Agg_Cluster'] = agg_clusters\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b47b02b",
   "metadata": {},
   "source": [
    "### Question-16  a. Find the optimal K Value using dendrogram for Agglomerative clustering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b2d026",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = hierarchy.linkage(df, method='ward')\n",
    "plt.figure(figsize=(10, 5))\n",
    "dn = hierarchy.dendrogram(Z)\n",
    "plt.title('Dendrogram for Agglomerative Clustering')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfa6020",
   "metadata": {},
   "source": [
    "### Question-16  b. Build a Agglomerative clustering model using the obtained optimal K value observed from dendrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7231d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_model = AgglomerativeClustering(n_clusters=3)\n",
    "agg_clusters = agg_model.fit_predict(scaled_features_df)\n",
    "plt.figure(figsize=(10, 5))\n",
    "Z = hierarchy.linkage(df, method='ward')\n",
    "df = hierarchy.dendrogram(Z)\n",
    "plt.title('Dendrogram for Agglomerative Clustering')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724bca29",
   "metadata": {},
   "source": [
    "### Question-16  c. Compute silhouette score for evaluating the quality of the Agglomerative clustering technique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7ca5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_avg = silhouette_score(scaled_features_df, agg_clusters)\n",
    "\n",
    "silhouette_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac9d8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_features_df.isna().sum().sum()\n",
    "np.isinf(scaled_features_df).sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb49bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(scaled_features_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2feea9",
   "metadata": {},
   "source": [
    "### Question-17  Perform cluster analysis by doing bivariate analysis between cluster labels and different features and write your conclusion on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4bc2b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(14, 5), facecolor='white')\n",
    "\n",
    "axs[0].scatter(df['size'], df['rating'], c=df['cluster'])\n",
    "axs[0].set_title('Rating vs Size')\n",
    "axs[0].set_xlabel('Size')\n",
    "axs[0].set_ylabel('Rating')\n",
    "\n",
    "linked = linkage(scaled_features_df, 'ward')\n",
    "dendrog\n",
    "\n",
    "features = ['rating', 'size']\n",
    "df_subset = df[features].dropna()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "standardized_data = scaler.fit_transform(data_subset)\n",
    "\n",
    "cluster = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward')\n",
    "cluster_labels = cluster.fit_predict(scaled_features_df)\n",
    "\n",
    "data_subset['cluster'] = cluster_labels\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 5), facecolor='white')\n",
    "\n",
    "axs[0].scatter(df['size'], df['rating'], c=df['cluster'])\n",
    "axs[0].set_title('Rating vs Size')\n",
    "axs[0].set_xlabel('Size')\n",
    "axs[0].set_ylabel('Rating')\n",
    "\n",
    "linked = linkage(scaled_features_df, 'ward')\n",
    "dendrogram(linked, ax=axs[1], truncate_mode='level', p=5)\n",
    "axs[1].set_title('Dendrogram')\n",
    "\n",
    "plt.tight_layout()\n",
    "fig, axs = plt.subplots(2)\n",
    "dendrogram(linked, ax=axs[0])\n",
    "dendrogram(linked, ax=axs[1], truncate_mode='level', p=5)\n",
    "\n",
    "axs[1].set_title('Dendrogram')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
